# -------------------------
# Backend server
# -------------------------
HOST=0.0.0.0
PORT=3001

# Postgres connection (optional; backend falls back to in-memory store when empty)
DATABASE_URL=postgres://user:password@localhost:5432/nexus

# Root directory for project workspaces (absolute or relative to repo root)
PROJECTS_ROOT=./projects

# Terminal idle timeout in milliseconds (0 disables idle shutdowns)
TERMINAL_IDLE_MS=600000

# -------------------------
# Frontend
# -------------------------
NEXT_PUBLIC_BACKEND_HTTP_BASE=http://localhost:3001
NEXT_PUBLIC_DEMO_USERNAME=demo
NEXT_PUBLIC_DEMO_PASSWORD=demo
NEXT_PUBLIC_DEMO_KEYFILE_TOKEN=

# -------------------------
# Model providers (set the one you use)
# -------------------------
OPENAI_API_KEY=
OPENAI_API_BASE=
ANTHROPIC_API_KEY=
QWEN_API_KEY=
MODEL_PROVIDER=openai

# -------------------------
# AI Integration (Managed Gemini CLI)
# -------------------------
# Enable AI-powered clarifications in meta-chat
ENABLE_AI=false

# Path to gemini CLI binary (defaults to 'gemini' in PATH)
# REQUIRED: Install from OuluBSD fork (includes TCP server mode)
# https://github.com/OuluBSD/managed-gemini-cli
GEMINI_CLI_PATH=gemini

# TCP port for gemini-cli server mode
GEMINI_TCP_PORT=7777

# Gemini model to use (e.g., gemini-2.5-flash, gemini-2.5-pro)
GEMINI_MODEL=gemini-2.5-flash
